# Navigating Object Orientation

Object Orientation came into existence to solve two software development problems that were frequently encountered prior to its introduction:

- Reliance on global variables, which led to a lot of change-this, break-that seemingly unrelated part of the code base.
- Redundant code generated by copy-and-pasting similar functionality in many different places, which led to the problem of when you wanted to change that part of the functionality, you had to track down all of the places it was implemented--a process that generally took things failing in production two or three times before you found all of them.

If we jump in the way-back machine, there was a time when everything lived in what has come to be called the "global" namespace.  Any part of the code base could access and modify anything else that was defined in the code base.

The first solution to this problem was the introduction of "functions" that had a "local" namespace.  Variables defined in one function could not be modified by another function.  This meant you were free to edit the individual functions safe in the knowledge that changing the value of a variable within a function will not break any of the other functions.

However, there was still a need to sometimes provide information that was available to many different functions, so it did not entirely remove the usage of "global" variables.  Change-this-break-that didn't happen as frequently, but it still happened.

Object Orientation sought to remove the reliance on global variables by introducing the concept of a "class".  A class is a self-contained collection of variables and functions that may or may not be accessible to other classes, depending on the level of exposure you, as the programmer, decide to give them.  Although, since they wanted to emphasize that the functions in a class should not be confused with what was formerly referred to as a function, they renamed "function" to "method".  The primary difference between a "function" and a "method" is that a "method" has automatic access to the "class variables" whereas a "function" does not.

In Object Oriented terms, this is referred to as "encapsulation", which simply means stuff defined inside a class cannot be manipulated by anything outside of the class.  Organizing code this way allows you to see everything that will be affected by changing a variable within the class.  It doesn't completely eliminate change-this-break-that, but it does get rid of the "break-that seemingly unrelated part of the code base"--you can only break things that are directly dependent on the class you are editing, which is much easier to track down.

Most Object Oriented languages provide keywords for designating the level of encapsulation an item will be given:

- private: The item is only accessible from within the class it is defined in.
- protected: The item is accessible within the class or any subclasses derived from the class.
- public: The item is available to anything in the code base that uses the class.

Python does not have keywords for enforcing encapsulation, so it is performed by convention:

- Prefixing an item with two underscores indicates it is private, and it should not be used anywhere except within the class it was defined.[^1]
- Prefixing an item with one underscore indicates it is protected, and it should not be used anywhere outside the class or any of it's subclasses.
- No underscore indicates the item is public.

[^1]:
    Python did implement name mangling for things prefixed with two underscores, so "private" is kind of enforced--you have to jump through some non-trivial introspective magic to get access to a "private" item outside of the class it's defined in. However, private was one of those things that made sense on a conceptual level, but in practice, it may not have been such a good idea.  Usage of it has led to the generation of copious amounts of redundant code.  The two lines of code you needed to modify to extend a class to suit you needs becomes hundreds of lines of code simply because the item you needed access to couldn't be reached by the subclass.  Because "private" is not really private in Python, and people are going to perform the ugly introspective magic rather than re-implement the entire class, the preference is to stick with "protected" and "public".

The other problem Object Orientation sought to address was the practice of copy-and-pasting chunks of code that provide similar functionality.

This problem was tackled by introducing the concept of "inheritance".  One class can be "derived" from another class, and the "derived" subclass will "inherit" all of the code defined in the class it is "derived" from.

We can take a look at how this works by working our way backwards through an inheritance tree.

```python linenums="1"
# standard library imports
import os

# repository imports
from repository.shell.delimited import SpaceDelimited

# application imports
from model.connection.postgresql import ServicePrincipal

# local imports
from .command import Command


class PgDump(Command):
    """
    Interacting with pg_dump.
    """

    @classmethod
    def dump_data(cls, *, connection_model: ServicePrincipal, path: str):
        """
        Pulls a SQL rendering of the data in the database to path.

        raises:
            Exception: If exit code is not zero.
        """
        command = SpaceDelimited(
            line=(
                "pg_dump",
                "-h",
                connection_model.host,
                "-p",
                str(connection_model.port),
                "-U",
                connection_model.service_principal_id,
                "--no-owner",
                "--data-only",
                connection_model.database,
                "--file",
                path,
            )
        )

        cls.execute(command=command, connection_model=connection_model)

    @classmethod
    def dump_roles(cls, *, connection_model: ServicePrincipal, path: str):
        """
        Pulls a SQL rendering of the roles in the database to path.

        raises:
            Exception: If exit code is not zero.
        """
        command = SpaceDelimited(
            line=(
                "pg_dumpall",
                "-h",
                connection_model.host,
                "-p",
                str(connection_model.port),
                "-U",
                connection_model.service_principal_id,
                "--quote-all-identifiers",
                "--no-role-passwords",
                "--roles-only",
                "--file",
                path,
            )
        )

        cls.execute(command=command, connection_model=connection_model)

    @classmethod
    def dump_schema(cls, *, connection_model: ServicePrincipal, path: str):
        """
        Pulls a SQL rendering of the schema for the database to path.  Ownership is not backed up.

        raises:
            Exception: If exit code is not zero.
        """
        command = SpaceDelimited(
            line=(
                "pg_dump",
                "-h",
                connection_model.host,
                "-p",
                str(connection_model.port),
                "-U",
                connection_model.service_principal_id,
                "--no-owner",
                "--schema-only",
                connection_model.database,
                "--file",
                path,
            )
        )

        cls.execute(command=command, connection_model=connection_model)

    @classmethod
    def execute(cls, *, command: SpaceDelimited, connection_model: ServicePrincipal):
        """
        Executes a pg_dump statement.
        """
        env = os.environ
        env["PGSSLMODE"] = "require"
        env["PGPASSWORD"] = connection_model.token.get_secret_value()

        super().execute(
            command=command,
            env=env,
        )
```

This is a Repository layer class that implements interactions with pg_dump--the command line tool for backing up PostgreSQL databases.

In the line that declares the class:

```python linenums="14"
class PgDump(Command):
```

The parenthetical component indicates the class is derived from the Command class, so, looking at the definition of Command (in an IDE, you would right-click on "Command" and select "Go to Definition"):


```python linenums="1"
# standard library imports
from datetime import datetime, UTC
from os import environ, _Environ
import subprocess


# repository imports
from state_machine import AbstractRepository
from repository.shell.delimited import SpaceDelimited


class Command(AbstractRepository):
    """
    Base class for executing command line actions.
    """

    @classmethod
    def execute(
        cls,
        *,
        command: SpaceDelimited,
        cwd: str | None = None,
        env: _Environ = environ,
        text: bool = True,
        start_new_session: bool = False,
        input: str | None = None,
    ) -> subprocess.CompletedProcess[str]:
        """
        Executes the command line action.

        raises:
            Exception: If exit code is not zero.
        """
        start_time = datetime.now(UTC)
        cls.logger.debug(f"  {command} - Started")

        result = subprocess.run(
            command.as_list(),
            capture_output=True,
            env=env,
            cwd=cwd,
            text=text,
            start_new_session=start_new_session,
            input=input,
        )

        end_time = datetime.now(UTC)
        if result.returncode != 0:
            cls.logger.debug(
                f"  {command} - Error: {result.returncode} - Runtime: {end_time - start_time}"
            )
            raise Exception(result.stderr)

        cls.logger.debug(f"  {command} - Completed - Runtime: {end_time - start_time}")

        return result
```

We have a general purpose definition of the "execute" method that works for all Repositories that require executing command-line actions.  The reason we don't want to re-implement this code in each individual Repository class is because there is standardized debug logging behavior we want all of the command-line interactions to use.  Were the logging code to be separately implemented in each Repository class, it wouldn't be "standardized".  Changing the "standard" or implementing a new command-line Repository would give plenty of opportunity for the code to drift away from the "standard".

Now then, looking at the class definition:

```python linenums="12"
class Command(AbstractRepository):
```

We see that Command itself is subclassed from AbstractRepository, so we'll take a quick look at the definition of AbstractRepository.

```python linenums="1"
# standard library imports
from typing import Any

# local imports
from .logger import Logger


class AbstractRepository:
    """
    Abstract base class for repositories.

    *logger* will be injected when accessing a repository action from a Dependency set of repositories for a machine.
    """

    logger: Logger

    @classmethod
    def execute(cls) -> Any:
        """
        Needs to be overriden in subclasses.  All actions taken by a repository should be executed in this method as
        this is the assumed mocking point for unit tests.
        """
        raise NotImplementedError()
```

The purpose of AbstractRepository is to support some rather down-in-the-weeds functionality that injects a logger object into a Repository class when it is used.

Interpreting AbstractRepository tells us that anything inheriting AbstractRepository will receive a logger property and be expected to implement an "execute" method.  What makes AbstractRepository "abstract" is that there isn't an implementation for the execute method.  In and of itself, this class doesn't do anything but identify one of its derivative classes as something that is coming from the Repository layer.

So the inheritance chain is:

- AbstractRepository provides the logger.
- Command provides a generalized implementation of the execute method.
- PgDump provides a specific implementation of the execute method to meet the additional requirements of pg_dump.

Which brings us to another Object Oriented concept, which is re-using parts of a class.  There are two ways of modifying the behavior of a class in a subclass.

- Extention: Adding new methods.
- Override: Changing the behavior of an inherited method.

The PgDump class exhibits both of these methods.  The dump_data and dump_schema methods are extentions of the Command class.  The execute method is an override of the execute method inherited from the Command class.

Taking a closer look at the execute method:

```python linenums="100"
    @classmethod
    def execute(cls, *, command: SpaceDelimited, connection_model: ServicePrincipal):
        """
        Executes a pg_dump statement.
        """
        env = os.environ
        env["PGSSLMODE"] = "require"
        env["PGPASSWORD"] = connection_model.token.get_secret_value()

        super().execute(
            command=command,
            env=env,
        )
```

We see that there was a modification in the calling parameters.  Command.execute has many parameters that are needed for the general functioning purposes, but of those, command is the only one needed one that is needed by the use case in PgDump.  However, pg_dump needs to be able to provide a password to authenticate with the PostgreSQL instance, so we needed an additional parameter to be able to provide that functionality.

*env["PGPASSWORD"] = connection_model.token.get_secret_value()* is where that is being used--the connection_model represents a Service Principal, and the "token" part of connection_model will go authenticate the Service Principal with Entra Id and fetch a token that will be used to authenticate with PostgreSQL, which is passed to the command-line interaction as an environmental variable.

The version of execute defined in Command is then called by using the special built-in function called super, which says "using the class variables and method definitions in the subclass, execute the code code of the method as it is defined in the super-class".

Additionally, pg_dump defaults to trying to establish a non-ssl connection to PostgreSQL which will fail, so we setup requiring ssl using a PostgreSQL environmental variable for the bash sub-process to execute the pg_dump command.

There is one final piece of magic, which is the @classmethod decorator.

All Object Oriented languages provide two kinds of methods:

- Instance methods: Methods that can only be called on an instantiated instance of a class.  These methods have full access to everything defined in the class, and they are inherited by subclasses.
- Static methods: Methods that can be called without instantiating the class.  These methods do not have access to anything defined in the class, and they are not inherited (they act like old-fashioned functions).

Python provides a type of method that is in between those two:  classmethods.  They can be called without instantiating the class, but they have access to properties defined at the class level (in this example, the logger object inherited from AbstractRepository).  They also have access to other classmethods defined in the class.  But most importantly, they can be inherited, so you can extend and override the same way you would with instance methods without having to re-implement everything the way you would with static methods.  In general, the usage of classmethods rather than static methods is preferred.

And this brings us to one final Object Oriented concept:  "instantiation".

Instantiation is the creation of a new object.  All object oriented languages support the concept of a "constructor" which provides the initialization of the class when it is instantiated.  In Python, the constructor is a special method called "\_\_init\_\_".

Looking at a classic Object Oriented example:

```python linenums="1"
import json

class Animal:
    @classmethod
    def from_json(cls, json_document):
        instantition_info = json.loads(json_document)
        return cls(
            sound=instantiation_info["sound"],
            number_of_toes=instantiation_info["number_of_toes"]
        )

    @classmethod
    def what_am_id(cls):
        return cls.__name__

    def __init__(self, sound, number_of_toes):
        self._sound = sound
        self._number_of_toes = number_of_toes

    def make_sound(self):
        return self._sound

    def how_many_toes(self):
        return self._number_of_toes

class Dog(Animal):
    def __init__(self, sound="bark", number_of_toes=20):
        super().__init__(sound=sound, number_of_toes=number_of_toes)

class Cat(Animal):
    def __init__(self, sound="meow", number_of_toes=20):
        super().__init__(sound=sound, number_of_toes=number_of_toes)
```

To instantiate a Dog, we would code it as:

```python
>>> dog = Dog()
>>> print(dog.make_sound())
bark
>>> print(dog.how_many_toes())
20
```

The classmethods are accessible on either the instance level or the class level:

```python
>> print(Dog.what_am_i())
Dog
>>> dog = Dog()
>>> print(dog.what_am_id())
Dog
```

However, calling an "instance" method that hasn't been instantiated will produce an error, because without instantiation, the "self" context doesn't exist.

```python
>>> Dog.make_sound()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: Dog.make_sound() missing 1 required positional argument: 'self'

```

This is telling us that the method expected to be called with "self" as the first parameter.  Under the hood, when Python calls an instance method on an instantiated object, it automatically includes the "self" context of the class as the first parameter.[^3]

[^3]:
  Technically, we could call the method if we provided a self context from another instantiated object, however, the use cases for doing that are very limited, and in general there is probably a better way of doing whatever you are trying to do.

When a class is used as a "callable"--parenthesis tacked on to the end of it--Python will execute the \_\_init\_\_ method. That's "instantiating" the class. An instantiated class is known as an "object", and that's where the "Object" in "Object Oriented" comes from.

We have two classmethods, and looking at the last one first:

```python
>>> print(Animal.what_am_i())
Animal
>>> print(Dog.what_am_i())
Dog
>>> print(Cat.what_am_i())
Cat
```

Obiously, it's that's a trivial thing to do, but it does demonstrate inheritance of classmethods.

The more common use case is is the other classmethod:  from_json.  This is what's know as a Factory[^4].  Factories wrap up commonly used ways of instantiating objects using alternative parameters to the ones provided by the constructor.

[^4]:
    The "all instantiations must be performed using factories" aspect of the Factory Pattern does not apply to Python.  Fortunately, Python was late enough to the Object Oriented party to recognize that the introduction of the "new" keywork used in other languages for instantiation was a mistake.  Using the Factory Pattern is the only way to instantiate objects--the constructor is just the default Factory.

In this case, we wanted to be able to instantiate an Animal from a json document.

```python
>>> seven_toed_cat = '{"sound": "meow", "number_of_toes": 28}'
>>> cat = Cat.from_json(json_document=seven_toed_cat)
>>> print(cat.make_sound())
meow
>>> print(cat.number_of_toes())
28
```

Another thing to note about methods and functions in general is the definition of default values.  For example, in the Dog class, we provided default values for the characteristics of a dog that are going to be true for most dogs.

```python
    def __init__(self, sound="bark", number_of_toes=20):
```

Had we not wanted to provide default values, the Animal tree could have been simplified:

```python linenums="1"
import json

class Animal:
    @classmethod
    def from_json(cls, json_document):
        instantition_info = json.loads(json_document)
        return cls(
            sound=instantiation_info["sound"],
            number_of_toes=instantiation_info["number_of_toes"]
        )

    @classmethod
    def what_am_id(cls):
        return cls.__name__

    def __init__(self, sound, number_of_toes):
        self._sound = sound
        self._number_of_toes = number_of_toes

    def make_sound(self):
        return self._sound

    def how_many_toes(self):
        return self._number_of_toes

class Dog(Animal):
    """Represents a dog."""

class Cat(Animal):
    """Represents a cat."""
```

The thing to note is that the implementations for \_\_init\_\_ are absent from Dog and Cat.  You don't have to implement a constructor unless the behavior of the constructor differs from the one inherited from the super-class.

Now, it's also possible to question why we would implement empty classes that don't differ from the super-class.  And, indeed, we could have implemented Animal as:

```python linenums="1"
import json

class Animal:
    @classmethod
    def from_json(cls, json_document):
        instantition_info = json.loads(json_document)
        return cls(
            sound=instantiation_info["sound"],
            number_of_toes=instantiation_info["number_of_toes"],
            animal_type=instantiation_info["animal_type"]
        )

    def __init__(self, sound, number_of_toes, animal_type):
        self._sound = sound
        self._number_of_toes = number_of_toes
        self._animal_type =  animal_type

    def make_sound(self):
        return self._sound

    def how_many_toes(self):
        return self._number_of_toes

    def what_am_id(cls):
        return self._animal_type
```

The reason for treating "animal type" as a class rather than a characteristic is that the code is often much more concise and less error prone when you can move information about the problem domain into the type system.

Say we wanted to add Fish to our pantheon of animals and wanted to know if the animal could breathe under water.  The version with the empty classes would become:

```python linenums="1"
from abc import abstractmethod
import json

class AbstractAnimal:
    @classmethod
    def from_json(cls, json_document):
        instantition_info = json.loads(json_document)
        return cls(
            sound=instantiation_info["sound"],
            number_of_toes=instantiation_info["number_of_toes"]
        )

    @classmethod
    def what_am_id(cls):
        return cls.__name__

    def __init__(self, sound, number_of_toes):
        self._sound = sound
        self._number_of_toes = number_of_toes

    @abstractmethod
    def can_breathe_under_water(self):
        """Needs to be implemeted in subclasses."""

    def make_sound(self):
        return self._sound

    def how_many_toes(self):
        return self._number_of_toes

class Dog(AbstractAnimal):
    """Represents a dog."""

    def can_breathe_under_water(self):
        return "No"

class Cat(AbstractAnimal):
    """Represents a cat."""

    def can_breathe_under_water(self):
        return "No"

class Fish(AbstractAnimal):
    """Represents a fish."""

    def can_breathe_under_water(self):
        return "Yes"
```

Comparing that to a single-Animal-with-animal-type implementation:

```python linenums="1"
import json

class Animal:
    @classmethod
    def from_json(cls, json_document):
        instantition_info = json.loads(json_document)
        return cls(
            sound=instantiation_info["sound"],
            number_of_toes=instantiation_info["number_of_toes"],
            animal_type=instantiation_info["animal_type"]
        )

    def __init__(self, sound, number_of_toes, animal_type):
        self._sound = sound
        self._number_of_toes = number_of_toes
        self._animal_type =  animal_type

    def can_breathe_under_water(self):
        if self._animal_type == "Dog":
            return "No"
        elif self._animal_type == "Cat":
            return "No"
        elif self._animal_type == "Fish":
            return "Yes"
        else:
            raise Exception(f"Unknown animal type {self._animal_type}")

    def make_sound(self):
        return self._sound

    def how_many_toes(self):
        return self._number_of_toes

    def what_am_id(cls):
        return self._animal_type
```

There are a number of problems with this implementation of can_breate_under_water.  It will continue to grow and become unwieldy as we add more animal types.  But the most egregious flaw is that it's very fragile.  The static type checker is not going to be able to let you know when you introduce an error into your code, which is easy to do with this kind of implementation.

```python
>>> fish = Animal(sound="glup", number_of_toes=0, animal_type="fish")
>>> fish.can_breathe_under_water()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/daniel.mcrae/develop/long-term-storage/animal.py", line 26, in can_breathe_under_water
    raise Exception(f"Unknown animal type {self._animal_type}")
Exception: Unknown animal type fish
```

When first looking at an Object Oriented code base, it's going to look like a splattered mess.  Object Orientation involves placing the functionality in a lot of different files, and usually, the base class definitions are not going to reside in the same directory as the sub-classed code that makes use of the base classes.  This is because the base class functionality is used in many different places throughout the code base.  There will be an overarching organizational scheme that facilitates figuring out what is supposed to live where (although if the code base has been around for a decade, you will probably find there are multiple organizational schemes layered on top each other--in which case, the code base genuinely is a splattered mess that will be difficult to learn).

As some general guidelines:

- If you find yourself copy-and-pasting similar functionality, think about parameterizing the functionality and putting it into a base class.  Python supports multiple inheritance, so you can mix-and-match functionality with "mix-ins".  "class Dog(AbstractAnimal, CanRunMixin)" inherits both the functionality of AbstractAnimal and the functionality describing animals that can run.
- If you find yourself generating a lengthy if ... elif ... elif ... else ... based on a property in a class, that property may be better implemented as individual types (in general, anything that allows static typing to catch potential implementation errors is the preferred approach).
- It is important to learn the pre-existing organizational scheme for the code base, and abide by it even if you think there is a better way of organizing the code.
- Right-click "Go to Definition" is your friend.